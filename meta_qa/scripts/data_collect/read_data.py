#!/usr/bin/env python3
"""
Read and visualize offline RL datasets.

This script reads HDF5 datasets generated by collect_data.py and provides:
- Dataset information and statistics
- Sample data inspection (observations, actions, rewards, costs, QA)
- Episode trajectory visualization (ego-centric view)
- Data distribution analysis

Visualization Features:
  Episode View (--visualize):
    - Ego-centric snapshot: history + future waypoints + surrounding vehicles
    - Velocity profile over time
    - Rewards & costs with event markers
    - Future trajectory reach analysis
  
  Distribution View (--visualize_dist):
    - Ego speed histogram
    - Future waypoints scatter plot
    - Historical positions distribution
    - Heading change analysis

Usage Examples:
    # Show dataset info
    python -m meta_qa.scripts.data_collect.read_data --file outputs/offline_data/original_qa.h5
    
    # List available datasets
    python -m meta_qa.scripts.data_collect.read_data --list
    
    # Visualize episode trajectory (ego-centric)
    python -m meta_qa.scripts.data_collect.read_data --file data.h5 --visualize --episode 5
    
    # Visualize data distributions
    python -m meta_qa.scripts.data_collect.read_data --file data.h5 --visualize_dist
    
    # Save visualizations
    python -m meta_qa.scripts.data_collect.read_data --file data.h5 --visualize --save_fig episode.png
    
    # Show QA annotations
    python -m meta_qa.scripts.data_collect.read_data --file data.h5 --show_qa --max_qa 10
"""

import os
import sys
import argparse
import json
import numpy as np
from typing import Dict, Any, List, Optional, Tuple

project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
sys.path.insert(0, project_root)

# Default output directory
DEFAULT_OUTPUT_DIR = os.path.join(project_root, "outputs", "offline_data")


class OfflineDataReader:
    """Reader for offline RL datasets."""
    
    def __init__(self, filepath: str):
        """
        Initialize reader.
        
        Args:
            filepath: Path to HDF5 or NPZ file
        """
        self.filepath = filepath
        self.data = {}
        self.attrs = {}
        self.qa_data = []
        self.frame_metadata = {}
        self.map_data = {}  # Per-episode map features
        
        self._load()
    
    def _load(self):
        """Load dataset from file."""
        if self.filepath.endswith('.h5'):
            self._load_hdf5()
        elif self.filepath.endswith('.npz'):
            self._load_npz()
        else:
            raise ValueError(f"Unsupported format: {self.filepath}")
    
    def _load_hdf5(self):
        """Load HDF5 dataset."""
        import h5py
        
        with h5py.File(self.filepath, 'r') as f:
            # Load main arrays
            for key in f.keys():
                if isinstance(f[key], h5py.Dataset):
                    self.data[key] = f[key][:]
                elif isinstance(f[key], h5py.Group):
                    # Handle groups
                    if key == 'qa_data':
                        # Load QA data
                        qa_grp = f['qa_data']
                        if 'items' in qa_grp:
                            qa_json = qa_grp['items'][()]
                            if isinstance(qa_json, bytes):
                                qa_json = qa_json.decode('utf-8')
                            self.qa_data = json.loads(qa_json)
                    elif key == 'frame_metadata':
                        # Load frame metadata
                        meta_grp = f['frame_metadata']
                        for mkey in meta_grp.keys():
                            raw = meta_grp[mkey][:]
                            # Decode byte strings from h5py
                            if raw.dtype.kind in ('S', 'O') or (hasattr(raw.dtype, 'char') and raw.dtype.char == 'S'):
                                self.frame_metadata[mkey] = np.array([
                                    x.decode('utf-8') if isinstance(x, bytes) else str(x) for x in raw
                                ])
                            else:
                                self.frame_metadata[mkey] = raw
                    elif key == 'map_data':
                        # Load map data (per-episode)
                        map_grp = f['map_data']
                        for ep_key in map_grp.keys():
                            ep_grp = map_grp[ep_key]
                            self.map_data[ep_key] = {
                                'points': ep_grp['points'][:],
                                'offsets': ep_grp['offsets'][:],
                                'types': ep_grp['types'][:],
                            }
            
            # Load attributes
            self.attrs = dict(f.attrs)
    
    def _load_npz(self):
        """Load NPZ dataset."""
        npz_data = np.load(self.filepath, allow_pickle=True)
        for key in npz_data.keys():
            self.data[key] = npz_data[key]
    
    @property
    def num_steps(self) -> int:
        """Total number of steps."""
        if 'observations' in self.data:
            return len(self.data['observations'])
        return 0
    
    @property
    def num_episodes(self) -> int:
        """Total number of episodes."""
        if 'episode_starts' in self.data:
            return len(self.data['episode_starts'])
        return self.attrs.get('total_episodes', 0)
    
    @property
    def obs_dim(self) -> int:
        """Observation dimension."""
        if 'observations' in self.data:
            return self.data['observations'].shape[1]
        return self.attrs.get('obs_dim', 0)
    
    @property
    def action_dim(self) -> int:
        """Action dimension."""
        if 'actions' in self.data:
            return self.data['actions'].shape[1]
        return self.attrs.get('action_dim', 0)
    
    @property
    def mode(self) -> str:
        """Collection mode / frequency."""
        return self.attrs.get('frequency', self.attrs.get('mode', 'unknown'))
    
    @property
    def has_cost(self) -> bool:
        """Whether dataset has cost information."""
        return 'costs' in self.data
    
    @property
    def has_qa(self) -> bool:
        """Whether dataset has QA data."""
        return len(self.qa_data) > 0
    
    @property
    def has_map(self) -> bool:
        """Whether dataset has map data."""
        return len(self.map_data) > 0
    
    @property
    def has_images(self) -> bool:
        """Whether dataset has camera image paths."""
        return 'image_CAM_FRONT' in self.frame_metadata
    
    @property
    def nuscenes_root(self) -> str:
        """NuScenes dataset root directory."""
        val = self.attrs.get('nuscenes_root', '')
        if isinstance(val, bytes):
            return val.decode('utf-8')
        return str(val) if val else ''
    
    CAMERA_ORDER = [
        'CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT',
        'CAM_BACK_LEFT',  'CAM_BACK',  'CAM_BACK_RIGHT',
    ]
    
    def get_image_paths(self, global_step_idx: int) -> Dict[str, str]:
        """
        Get camera image paths for a specific global step.
        
        Args:
            global_step_idx: Global step index in the dataset
            
        Returns:
            Dict of camera_name -> full image path
        """
        paths = {}
        root = self.nuscenes_root
        for cam in self.CAMERA_ORDER:
            key = f'image_{cam}'
            if key in self.frame_metadata:
                rel = self.frame_metadata[key][global_step_idx]
                if rel and rel != '':
                    full = os.path.join(root, rel) if root else rel
                    paths[cam] = full
        return paths
    
    def get_episode_range(self, episode_idx: int) -> Tuple[int, int]:
        """
        Get start and end indices for an episode.
        
        Args:
            episode_idx: Episode index
            
        Returns:
            (start_idx, end_idx) tuple
        """
        if 'episode_starts' not in self.data:
            return 0, self.num_steps
        
        starts = self.data['episode_starts']
        start_idx = starts[episode_idx]
        
        if episode_idx < len(starts) - 1:
            end_idx = starts[episode_idx + 1]
        else:
            end_idx = self.num_steps
        
        return int(start_idx), int(end_idx)
    
    def get_episode_data(self, episode_idx: int) -> Dict[str, np.ndarray]:
        """
        Get data for a specific episode.
        
        Args:
            episode_idx: Episode index
            
        Returns:
            Dictionary with episode data
        """
        start, end = self.get_episode_range(episode_idx)
        
        episode_data = {}
        for key, value in self.data.items():
            if key == 'episode_starts':
                continue
            if isinstance(value, np.ndarray) and len(value) == self.num_steps:
                episode_data[key] = value[start:end]
        
        return episode_data
    
    def get_qa_for_step(self, step_idx: int) -> List[Dict]:
        """Get QA items for a specific step."""
        return [qa for qa in self.qa_data if qa.get('step_index') == step_idx]
    
    def _find_nearest_qa(self, global_step_idx: int, search_range: int = 30) -> List[Dict]:
        """
        Find QA items for the given step or the nearest keyframe with QA.
        
        First checks exactly at global_step_idx, then searches nearby keyframes.
        
        Args:
            global_step_idx: Global step index in the dataset
            search_range: Max steps to search in each direction
            
        Returns:
            List of QA dicts (may be empty)
        """
        # Direct match
        direct = self.get_qa_for_step(global_step_idx)
        if direct:
            return direct
        
        # Search nearby steps (prefer closest)
        for offset in range(1, search_range + 1):
            for idx in [global_step_idx - offset, global_step_idx + offset]:
                if 0 <= idx < self.num_steps:
                    qa = self.get_qa_for_step(idx)
                    if qa:
                        return qa
        return []
    
    def print_info(self):
        """Print dataset information."""
        print("=" * 70)
        print(f"Dataset: {os.path.basename(self.filepath)}")
        print("=" * 70)
        
        # Metadata
        print("\nMetadata:")
        print("-" * 50)
        for key, value in sorted(self.attrs.items()):
            print(f"  {key}: {value}")
        
        # Data arrays
        print("\nData Arrays:")
        print("-" * 50)
        for key, value in sorted(self.data.items()):
            if isinstance(value, np.ndarray):
                dtype_str = str(value.dtype)
                shape_str = str(value.shape)
                if value.size > 0:
                    if np.issubdtype(value.dtype, np.floating):
                        range_str = f"[{value.min():.4f}, {value.max():.4f}], mean={value.mean():.4f}"
                    elif np.issubdtype(value.dtype, np.integer):
                        range_str = f"[{value.min()}, {value.max()}]"
                    elif value.dtype == bool:
                        range_str = f"True: {value.sum()}"
                    else:
                        range_str = ""
                    print(f"  {key}: {shape_str} ({dtype_str}) {range_str}")
                else:
                    print(f"  {key}: {shape_str} ({dtype_str})")
        
        # Frame metadata
        if self.frame_metadata:
            print("\nFrame Metadata:")
            print("-" * 50)
            for key, value in self.frame_metadata.items():
                if isinstance(value, np.ndarray):
                    print(f"  {key}: shape={value.shape}")
        
        # QA data
        if self.qa_data:
            print(f"\nQA Data: {len(self.qa_data)} items")
        
        # Map data
        if self.map_data:
            print(f"\nMap Data: {len(self.map_data)} episodes with map features")
            for ep_key, mp in sorted(self.map_data.items()):
                n_feats = len(mp['types'])
                n_pts = len(mp['points'])
                print(f"  {ep_key}: {n_feats} features, {n_pts} points")
        
        # Statistics
        print("\nStatistics:")
        print("-" * 50)
        print(f"  Total steps: {self.num_steps}")
        print(f"  Total episodes: {self.num_episodes}")
        if self.num_episodes > 0:
            print(f"  Avg episode length: {self.num_steps / self.num_episodes:.1f}")
        print(f"  Observation dim: {self.obs_dim}")
        print(f"  Action dim: {self.action_dim}")
        
        if 'rewards' in self.data:
            rewards = self.data['rewards']
            print(f"  Total reward: {rewards.sum():.2f}")
            print(f"  Avg reward/step: {rewards.mean():.4f}")
        
        if self.has_cost:
            costs = self.data['costs']
            print(f"  Total cost: {costs.sum():.2f}")
            print(f"  Avg cost/step: {costs.mean():.4f}")
            print(f"  Steps with cost > 0: {(costs > 0).sum()} ({100*(costs > 0).mean():.1f}%)")
    
    def print_samples(self, n_samples: int = 3, start_idx: int = 0):
        """Print sample data points."""
        print("\n" + "=" * 70)
        print(f"Sample Data (steps {start_idx} to {start_idx + n_samples - 1})")
        print("=" * 70)
        
        n = min(n_samples, self.num_steps - start_idx)
        
        for i in range(start_idx, start_idx + n):
            print(f"\n--- Step {i} ---")
            
            # Frame metadata
            if self.frame_metadata:
                if 'is_sample' in self.frame_metadata:
                    is_sample = self.frame_metadata['is_sample'][i]
                    print(f"  Is Sample (keyframe): {is_sample}")
                if 'timestamps' in self.frame_metadata:
                    ts = self.frame_metadata['timestamps'][i]
                    print(f"  Timestamp: {ts / 1e6:.3f}s")
                if 'interpolation_ratios' in self.frame_metadata:
                    ratio = self.frame_metadata['interpolation_ratios'][i]
                    print(f"  Interpolation: {ratio:.2%}")
            
            # Observation
            if 'observations' in self.data:
                obs = self.data['observations'][i]
                print(f"  Observation: shape={obs.shape}")
                # Show first few values
                print(f"    First 10 values: {obs[:10]}")
            
            # Action
            if 'actions' in self.data:
                act = self.data['actions'][i]
                action_dim = self.attrs.get('action_dim', len(act))
                
                # Determine action format
                if action_dim == 40:
                    # 20 waypoints * 2 (x, y)
                    waypoints = act.reshape(-1, 2)
                    print(f"  Action: {len(waypoints)} waypoints (x, y)")
                    print(f"    First: ({waypoints[0, 0]:.2f}, {waypoints[0, 1]:.2f})")
                    print(f"    Last:  ({waypoints[-1, 0]:.2f}, {waypoints[-1, 1]:.2f})")
                elif action_dim % 5 == 0:
                    # Trajectory waypoints * 5 (x, y, vx, vy, heading)
                    n_wp = action_dim // 5
                    waypoints = act.reshape(n_wp, 5)
                    print(f"  Action: {n_wp} waypoints (x, y, vx, vy, heading)")
                    print(f"    First: pos=({waypoints[0, 0]:.2f}, {waypoints[0, 1]:.2f}), "
                          f"vel=({waypoints[0, 2]:.2f}, {waypoints[0, 3]:.2f}), "
                          f"heading={waypoints[0, 4]:.2f}")
                else:
                    print(f"  Action: {act[:10]}...")
            
            # Reward & Cost
            if 'rewards' in self.data:
                print(f"  Reward: {self.data['rewards'][i]:.4f}")
            if 'costs' in self.data:
                print(f"  Cost: {self.data['costs'][i]:.4f}")
            if 'terminals' in self.data:
                print(f"  Terminal: {self.data['terminals'][i]}")
            
            # QA
            qa_items = self.get_qa_for_step(i)
            if qa_items:
                print(f"  QA Items: {len(qa_items)}")
                for qa in qa_items[:2]:
                    q = qa.get('question', '')[:50]
                    a = str(qa.get('answer', ''))[:30]
                    print(f"    Q: {q}...")
                    print(f"    A: {a}")
    
    def print_qa_data(self, max_items: int = 20):
        """Print QA data."""
        if not self.qa_data:
            print("No QA data in this dataset")
            return
        
        print("\n" + "=" * 70)
        print(f"QA Data ({len(self.qa_data)} total items, showing first {min(max_items, len(self.qa_data))})")
        print("=" * 70)
        
        for i, qa in enumerate(self.qa_data[:max_items]):
            print(f"\n--- QA Item {i} ---")
            print(f"  Step: {qa.get('step_index', 'N/A')}")
            print(f"  Scene: {qa.get('scene', 'N/A')}")
            print(f"  Sample Index: {qa.get('sample_index', 'N/A')}")
            print(f"  Template Type: {qa.get('template_type', qa.get('question_type', 'N/A'))}")
            print(f"  Question: {qa.get('question', 'N/A')}")
            print(f"  Answer: {qa.get('answer', 'N/A')}")
        
        if len(self.qa_data) > max_items:
            print(f"\n... and {len(self.qa_data) - max_items} more QA items")
    
    def _decode_trajectory_obs(self, obs: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        Decode trajectory-based observation into ego history and surrounding vehicles.
        
        Observation layout:
            [ego_history (H×5)] [vehicle_0 (H×5)] ... [vehicle_N (H×5)]
        
        Each entry: (x, y, vx, vy, heading) in local ego-centric frame.
        The last row of ego_history (current step) should be near (0, 0, vx, vy, 0).
        
        Returns:
            ego_history: (history_steps, 5) — ego trajectory history
            vehicle_history: (max_vehicles, history_steps, 5) — surrounding vehicles
        """
        history_steps = int(self.attrs.get('history_steps', 6))
        max_vehicles = int(self.attrs.get('max_vehicles', 10))
        EGO_DIM = 5
        VEHICLE_DIM = 5
        
        ego_total = history_steps * EGO_DIM
        ego_history = obs[:ego_total].reshape(history_steps, EGO_DIM)
        
        vehicle_flat = obs[ego_total:]
        expected_vehicle_dim = max_vehicles * history_steps * VEHICLE_DIM
        if len(vehicle_flat) >= expected_vehicle_dim:
            vehicle_history = vehicle_flat[:expected_vehicle_dim].reshape(
                max_vehicles, history_steps, VEHICLE_DIM
            )
        else:
            vehicle_history = np.zeros((max_vehicles, history_steps, VEHICLE_DIM))
        
        return ego_history, vehicle_history
    
    def _decode_trajectory_action(self, action: np.ndarray) -> np.ndarray:
        """
        Decode trajectory action into future waypoints.
        
        Action layout:
            future_steps × (rel_x, rel_y, rel_vx, rel_vy, heading) in local frame.
        
        Returns:
            waypoints: (future_steps, 5)
        """
        future_steps = int(self.attrs.get('future_steps', 24))
        WAYPOINT_DIM = 5
        
        expected = future_steps * WAYPOINT_DIM
        if len(action) >= expected:
            return action[:expected].reshape(future_steps, WAYPOINT_DIM)
        else:
            return action.reshape(-1, WAYPOINT_DIM)
    
    def _is_trajectory_format(self) -> bool:
        """Check if dataset uses trajectory-based observation/action format."""
        return 'history_steps' in self.attrs and 'future_steps' in self.attrs
    
    def _get_map_features_local(self, episode_idx: int, step_idx_in_episode: int,
                                 radius: float = 60.0) -> List[Tuple[np.ndarray, int]]:
        """
        Get nearby map features transformed to ego-local frame at a specific step.
        
        Args:
            episode_idx: Episode index
            step_idx_in_episode: Step index within the episode
            radius: Filter radius around ego (meters)
            
        Returns:
            List of (points_local, type_code) tuples, where points_local is (N, 2)
        """
        ep_key = f'episode_{episode_idx}'
        if ep_key not in self.map_data:
            return []
        
        # Get ego world position and heading at this step
        start, _ = self.get_episode_range(episode_idx)
        global_idx = start + step_idx_in_episode
        
        if ('ego_world_x' not in self.frame_metadata or
            'ego_world_y' not in self.frame_metadata or
            'ego_world_heading' not in self.frame_metadata):
            return []
        
        ego_x = float(self.frame_metadata['ego_world_x'][global_idx])
        ego_y = float(self.frame_metadata['ego_world_y'][global_idx])
        ego_h = float(self.frame_metadata['ego_world_heading'][global_idx])
        ego_pos = np.array([ego_x, ego_y])
        cos_h, sin_h = np.cos(-ego_h), np.sin(-ego_h)
        
        map_ep = self.map_data[ep_key]
        points = map_ep['points']     # (total_pts, 2) world coords
        offsets = map_ep['offsets']    # (num_feats + 1,)
        types = map_ep['types']       # (num_feats,)
        
        result = []
        for i in range(len(types)):
            feat_pts = points[offsets[i]:offsets[i + 1]]  # (N, 2) world coords
            
            # Quick bounding box check
            feat_center = feat_pts.mean(axis=0)
            if np.linalg.norm(feat_center - ego_pos) > radius + 50:
                continue
            
            # Transform to ego-local frame
            rel = feat_pts - ego_pos
            local_x = rel[:, 0] * cos_h - rel[:, 1] * sin_h
            local_y = rel[:, 0] * sin_h + rel[:, 1] * cos_h
            local_pts = np.column_stack([local_x, local_y])
            
            # Filter: keep only features with at least one point within radius
            dists = np.linalg.norm(local_pts, axis=1)
            if dists.min() > radius:
                continue
            
            result.append((local_pts, int(types[i])))
        
        return result
    
    def visualize_episode(self, episode_idx: int = 0, save_path: Optional[str] = None):
        """
        Visualize an episode's trajectory data.
        
        For trajectory-based format:
          - Row 1: Ego-centric view | Velocity profile
          - Row 2: Rewards & costs | Vehicle dynamics (accel, yaw rate)
          - Row 3: 6 surround camera images (2×3 grid)
          - Row 4: QA annotations for the snapshot's nearest keyframe
        
        Uses color scheme from trajectory_vis.py:
          - Green: predicted/future trajectory
          - Blue:  actual/historical trajectory
          - Red:   ground truth / surrounding vehicles
        
        Args:
            episode_idx: Episode index to visualize
            save_path: Optional path to save the figure
        """
        try:
            import matplotlib.pyplot as plt
            import matplotlib.gridspec as gridspec
            from matplotlib.lines import Line2D
            from matplotlib.patches import Polygon as MplPolygon
            from matplotlib.collections import PatchCollection
        except ImportError:
            print("Error: matplotlib required for visualization")
            print("Install with: pip install matplotlib")
            return
        
        if episode_idx >= self.num_episodes:
            print(f"Error: Episode {episode_idx} not found (max: {self.num_episodes - 1})")
            return
        
        episode_data = self.get_episode_data(episode_idx)
        start, end = self.get_episode_range(episode_idx)
        
        observations = episode_data.get('observations', np.array([]))
        actions = episode_data.get('actions', np.array([]))
        
        if len(observations) == 0 or len(actions) == 0:
            print("No observation/action data to visualize")
            return
        
        n_steps = len(observations)
        print(f"\nVisualizing Episode {episode_idx} (steps {start}-{end-1}, {n_steps} steps)")
        
        # Color scheme (matching trajectory_vis.py / config.py, normalized to 0-1)
        COLOR_HISTORY = np.array([0, 0, 255]) / 255.0      # Blue — actual/historical path
        COLOR_FUTURE = np.array([0, 255, 0]) / 255.0       # Green — predicted/future
        COLOR_VEHICLE = np.array([255, 0, 0]) / 255.0      # Red — surrounding vehicles
        COLOR_EGO = np.array([255, 255, 0]) / 255.0        # Yellow — current ego
        
        is_traj = self._is_trajectory_format()
        
        # Determine if we have camera images / QA to show in extra rows
        show_cameras = self.has_images
        show_qa_row = self.has_qa
        show_extra = show_cameras or show_qa_row
        
        # Build figure with GridSpec
        # Row 0-1: original 2×2 charts
        # Row 2: 6 camera images (2×3)  [optional]
        # Row 3: QA annotations text     [optional]
        if show_extra:
            n_grid_rows = 2  # base
            height_ratios = [3, 3]
            if show_cameras:
                n_grid_rows += 2  # 2 rows for cameras (front + back)
                height_ratios += [2, 2]
            if show_qa_row:
                n_grid_rows += 1
                height_ratios += [1.8]
            fig = plt.figure(figsize=(16, sum(height_ratios) * 2.2 + 1))
            gs = gridspec.GridSpec(n_grid_rows, 6, figure=fig,
                                  height_ratios=height_ratios,
                                  hspace=0.35, wspace=0.3)
            # Top 2×2 charts share a 2-row × 6-col grid, each chart takes 3 cols
            ax1 = fig.add_subplot(gs[0, 0:3])
            ax2 = fig.add_subplot(gs[0, 3:6])
            ax3 = fig.add_subplot(gs[1, 0:3])
            ax4 = fig.add_subplot(gs[1, 3:6])
        else:
            fig, axes = plt.subplots(2, 2, figsize=(16, 13))
            ax1, ax2 = axes[0, 0], axes[0, 1]
            ax3, ax4 = axes[1, 0], axes[1, 1]
        
        # Pick a representative timestep near the middle of the episode
        snap_idx = n_steps // 2
        
        # ================================================================
        # Plot 1: Ego-Centric Trajectory Snapshot (single timestep)
        # ================================================================
        
        if is_traj:
            
            ego_hist, vehicles = self._decode_trajectory_obs(observations[snap_idx])
            future_wp = self._decode_trajectory_action(actions[snap_idx])
            
            # --- Map features (background layer) ---
            # Map type styling: {type_code: (color, linestyle, linewidth, alpha, label)}
            MAP_STYLE = {
                0: ('#A0A0A0', '-',  1.2, 0.5, 'Lane (street)'),       # LANE_SURFACE_STREET
                1: ('#B0B0B0', '--', 1.0, 0.4, 'Lane (unstruct.)'),    # LANE_SURFACE_UNSTRUCTURE
                2: ('#FFFFFF', '-',  1.0, 0.6, 'Road line (white)'),    # ROAD_LINE_SOLID_SINGLE_WHITE
                3: ('#FFFFFF', '--', 0.8, 0.5, 'Road line (dashed)'),   # ROAD_LINE_BROKEN_SINGLE_WHITE
                4: ('#FFD700', '-',  1.0, 0.6, 'Road line (yellow)'),   # ROAD_LINE_SOLID_SINGLE_YELLOW
                5: ('#8B7355', '-',  1.5, 0.4, 'Road edge'),            # ROAD_EDGE_SIDEWALK
                6: ('#87CEEB', '-',  1.0, 0.3, 'Crosswalk'),            # CROSSWALK
            }
            
            if self.has_map:
                # Get map features in ego-local frame
                view_radius = 60.0
                map_features_local = self._get_map_features_local(
                    episode_idx, snap_idx, radius=view_radius
                )
                
                drawn_types = set()
                for pts_local, type_code in map_features_local:
                    style = MAP_STYLE.get(type_code, ('#808080', '-', 0.5, 0.3, 'Other'))
                    color, ls, lw, alpha, label = style
                    
                    # Draw crosswalks as filled polygons
                    if type_code == 6 and len(pts_local) >= 3:
                        poly = MplPolygon(pts_local, closed=True,
                                         facecolor='#87CEEB', edgecolor='#5FAEC5',
                                         alpha=0.2, linewidth=0.5, zorder=1)
                        ax1.add_patch(poly)
                    # Draw road edges as thick lines
                    elif type_code == 5:
                        ax1.plot(pts_local[:, 0], pts_local[:, 1],
                                 color=color, linestyle=ls, linewidth=lw,
                                 alpha=alpha, zorder=1)
                    # Draw lanes and road lines
                    else:
                        ax1.plot(pts_local[:, 0], pts_local[:, 1],
                                 color=color, linestyle=ls, linewidth=lw,
                                 alpha=alpha, zorder=1)
                    
                    drawn_types.add(type_code)
            
            # --- Ego history (blue dashed, trailing behind) ---
            hist_mask = np.any(ego_hist[:, :2] != 0, axis=1)
            if hist_mask.any():
                hist_pts = ego_hist[hist_mask, :2]
                # Include origin so the line connects to ego
                pts = np.vstack([hist_pts, [0, 0]])
                ax1.plot(pts[:, 0], pts[:, 1],
                         color=COLOR_HISTORY, linestyle='--', linewidth=2, alpha=0.8)
                ax1.scatter(hist_pts[:, 0], hist_pts[:, 1],
                            color=COLOR_HISTORY, s=25, alpha=0.7, zorder=3)
            
            # --- Future trajectory (green solid, ahead) ---
            future_pts = future_wp[:, :2]
            if np.any(future_pts != 0):
                full_future = np.vstack([[0, 0], future_pts])
                ax1.plot(full_future[:, 0], full_future[:, 1],
                         color=COLOR_FUTURE, linestyle='-', linewidth=2.5, alpha=0.9)
                # Waypoint dots with increasing size
                sizes = np.linspace(20, 50, len(future_pts))
                ax1.scatter(future_pts[:, 0], future_pts[:, 1],
                            color=COLOR_FUTURE, s=sizes, alpha=0.8, zorder=3)
                # Mark final waypoint
                ax1.scatter(future_pts[-1, 0], future_pts[-1, 1],
                            color=COLOR_FUTURE, s=80, marker='D',
                            edgecolors='white', linewidths=0.8, alpha=0.9, zorder=4)
            
            # --- Current ego position (yellow, center) ---
            ax1.scatter(0, 0, color=COLOR_EGO, s=120, marker='o',
                        edgecolors='black', linewidths=1.2, zorder=6)
            
            # --- Ego heading arrow ---
            ego_heading = ego_hist[-1, 4]  # current heading (should be ~0)
            arrow_len = 2.0
            ax1.annotate('', xy=(arrow_len * np.cos(ego_heading),
                                  arrow_len * np.sin(ego_heading)),
                         xytext=(0, 0),
                         arrowprops=dict(arrowstyle='->', color=COLOR_EGO,
                                         lw=2, mutation_scale=15))
            
            # --- Surrounding vehicles (red markers with history trails) ---
            for v_idx in range(vehicles.shape[0]):
                # Current position
                veh_pos = vehicles[v_idx, -1, :2]
                if np.linalg.norm(veh_pos) < 0.01:
                    continue
                ax1.scatter(veh_pos[0], veh_pos[1],
                            color=COLOR_VEHICLE, s=60, marker='s',
                            edgecolors='darkred', linewidths=0.8, alpha=0.8, zorder=4)
                # Vehicle history trail (thin red dashed)
                veh_hist_mask = np.any(vehicles[v_idx, :, :2] != 0, axis=1)
                if veh_hist_mask.sum() > 1:
                    veh_trail = vehicles[v_idx, veh_hist_mask, :2]
                    ax1.plot(veh_trail[:, 0], veh_trail[:, 1],
                             color=COLOR_VEHICLE, linestyle=':', linewidth=1, alpha=0.4)
            
            # Legend
            legend_elements = [
                Line2D([0], [0], color=COLOR_HISTORY, linestyle='--', linewidth=2, label='Ego History'),
                Line2D([0], [0], color=COLOR_FUTURE, linestyle='-', linewidth=2.5, label='Future Waypoints'),
                Line2D([0], [0], color=COLOR_EGO, marker='o', linestyle='None',
                       markersize=9, markeredgecolor='black', label='Ego (center)'),
                Line2D([0], [0], color=COLOR_VEHICLE, marker='s', linestyle='None',
                       markersize=7, markeredgecolor='darkred', label='Surrounding'),
            ]
            # Add map legend entries if map features were drawn
            if self.has_map and 'drawn_types' in dir() and drawn_types:
                map_legend_items = [
                    (0, '#A0A0A0', '-',  'Lanes'),
                    (2, '#FFFFFF', '-',  'Road Lines'),
                    (5, '#8B7355', '-',  'Road Edges'),
                    (6, '#87CEEB', '-',  'Crosswalks'),
                ]
                for tc, color, ls, label in map_legend_items:
                    if tc in drawn_types or (tc == 0 and (0 in drawn_types or 1 in drawn_types)) or \
                       (tc == 2 and any(t in drawn_types for t in [2, 3, 4])):
                        legend_elements.append(
                            Line2D([0], [0], color=color, linestyle=ls, linewidth=1.2,
                                   alpha=0.7, label=label)
                        )
            ax1.legend(handles=legend_elements, loc='upper left', fontsize=7)
            ax1.set_title(f'Ego-Centric View (step {snap_idx + start})', fontsize=11)
            
            # --- Set axis limits based on ego trajectory range + padding ---
            # Collect all ego-related points (history + future)
            ego_pts_list = [[0, 0]]  # ego origin
            if hist_mask.any():
                ego_pts_list.extend(ego_hist[hist_mask, :2].tolist())
            if np.any(future_pts != 0):
                ego_pts_list.extend(future_pts.tolist())
            ego_pts_arr = np.array(ego_pts_list)
            
            x_min, x_max = ego_pts_arr[:, 0].min(), ego_pts_arr[:, 0].max()
            y_min, y_max = ego_pts_arr[:, 1].min(), ego_pts_arr[:, 1].max()
            
            # Ensure minimum range and add padding
            x_range = max(x_max - x_min, 5.0)
            y_range = max(y_max - y_min, 5.0)
            pad = max(x_range, y_range) * 0.3 + 3.0  # proportional + fixed padding
            
            cx = (x_min + x_max) / 2
            cy = (y_min + y_max) / 2
            half = max(x_range, y_range) / 2 + pad
            ax1.set_xlim(cx - half, cx + half)
            ax1.set_ylim(cy - half, cy + half)
        else:
            ax1.text(0.5, 0.5, 'Non-trajectory format\n(no snapshot view)',
                     ha='center', va='center', transform=ax1.transAxes, fontsize=12)
            ax1.set_title(f'Episode {episode_idx}')
        
        ax1.set_xlabel('X (m, ego frame)')
        ax1.set_ylabel('Y (m, ego frame)')
        ax1.set_aspect('equal')
        ax1.grid(True, alpha=0.2)
        ax1.axhline(y=0, color='gray', linewidth=0.5, alpha=0.3)
        ax1.axvline(x=0, color='gray', linewidth=0.5, alpha=0.3)
        
        # Set dark background when map features are drawn for better contrast
        if self.has_map and is_traj:
            ax1.set_facecolor('#2C2C2C')
            ax1.tick_params(colors='#CCCCCC')
            ax1.xaxis.label.set_color('#CCCCCC')
            ax1.yaxis.label.set_color('#CCCCCC')
            ax1.title.set_color('#EEEEEE')
        
        # ================================================================
        # Plot 2: Velocity Profile
        # ================================================================
        
        if is_traj:
            speeds = []
            vx_list = []
            vy_list = []
            for i in range(n_steps):
                ego_hist, _ = self._decode_trajectory_obs(observations[i])
                # Current step is the last row in ego history
                vx = ego_hist[-1, 2]
                vy = ego_hist[-1, 3]
                vx_list.append(vx)
                vy_list.append(vy)
                speeds.append(np.sqrt(vx**2 + vy**2))
            
            steps = np.arange(n_steps)
            ax2.plot(steps, speeds, color='#2196F3', linewidth=1.5, label='Speed |v|')
            ax2.fill_between(steps, 0, speeds, color='#2196F3', alpha=0.15)
            ax2.plot(steps, vx_list, color='#4CAF50', linewidth=1, alpha=0.7, label='vx (local)')
            ax2.plot(steps, vy_list, color='#FF9800', linewidth=1, alpha=0.7, label='vy (local)')
            ax2.set_title('Velocity Profile', fontsize=11)
            ax2.set_ylabel('Velocity (m/s)')
            ax2.legend(fontsize=8)
        else:
            ax2.text(0.5, 0.5, 'Non-trajectory format',
                     ha='center', va='center', transform=ax2.transAxes)
            ax2.set_title('Velocity')
        
        ax2.set_xlabel('Step')
        ax2.grid(True, alpha=0.2)
        ax2.axhline(y=0, color='gray', linestyle='--', linewidth=0.5)
        
        # ================================================================
        # Plot 3: Rewards & Costs
        # ================================================================
        steps = np.arange(n_steps)
        
        has_reward = 'rewards' in episode_data
        has_cost = 'costs' in episode_data
        
        if has_reward:
            rewards = episode_data['rewards']
            ax3.plot(steps, rewards, color='#2196F3', linewidth=1.2, label='Reward')
            ax3.fill_between(steps, 0, rewards, color='#2196F3', alpha=0.15)
        
        if has_cost:
            costs = episode_data['costs']
            ax3_cost = ax3.twinx()
            ax3_cost.plot(steps, costs, color='#F44336', linewidth=1.2, label='Cost')
            ax3_cost.fill_between(steps, 0, costs, color='#F44336', alpha=0.15)
            ax3_cost.set_ylabel('Cost', color='#F44336', fontsize=10)
            ax3_cost.tick_params(axis='y', labelcolor='#F44336')
            # Mark steps with non-zero cost
            cost_steps = np.where(costs > 0)[0]
            if len(cost_steps) > 0:
                ax3.axvspan(cost_steps[0], cost_steps[-1], alpha=0.05, color='red')
                for cs in cost_steps:
                    ax3.axvline(x=cs, color='#F44336', linewidth=0.3, alpha=0.3)
        
        if has_reward or has_cost:
            # Combine legends
            lines = []
            labels = []
            if has_reward:
                lines.append(Line2D([0], [0], color='#2196F3', linewidth=1.5))
                labels.append(f'Reward (avg={rewards.mean():.3f})')
            if has_cost:
                lines.append(Line2D([0], [0], color='#F44336', linewidth=1.5))
                labels.append(f'Cost (sum={costs.sum():.2f}, {(costs > 0).sum()} events)')
            ax3.legend(lines, labels, fontsize=8, loc='upper right')
        else:
            ax3.text(0.5, 0.5, 'No reward/cost data',
                     ha='center', va='center', transform=ax3.transAxes)
        
        ax3.set_xlabel('Step')
        ax3.set_ylabel('Reward', color='#2196F3', fontsize=10)
        ax3.tick_params(axis='y', labelcolor='#2196F3')
        ax3.set_title('Rewards & Costs', fontsize=11)
        ax3.grid(True, alpha=0.2)
        
        # ================================================================
        # Plot 4: Dynamics (Acceleration & Yaw Rate)
        # ================================================================
        
        if is_traj:
            # 1. Calculate Speeds (Recalculate or gather from Plot 2 logic)
            step_speeds = []
            for i in range(n_steps):
                ego_hist, _ = self._decode_trajectory_obs(observations[i])
                vx, vy = ego_hist[-1, 2], ego_hist[-1, 3]
                step_speeds.append(np.sqrt(vx**2 + vy**2))
            step_speeds = np.array(step_speeds)
            
            # 2. Get Timestamps & Calculate Time Deltas
            # We construct a clean time axis to ensure determining gradients is safe
            # (avoiding divide-by-zero from duplicate timestamps)
            dt_diffs = np.ones(n_steps - 1) * 0.1  # Default 10Hz intervals
            
            if 'timestamps' in self.frame_metadata:
                ep_ts = self.frame_metadata['timestamps'][start:end]
                if len(ep_ts) == n_steps:
                    ts_sec = ep_ts / 1e6
                    raw_diffs = np.diff(ts_sec)
                    # Protect against zero/small dt
                    dt_diffs = np.where(raw_diffs < 1e-4, 0.1, raw_diffs)

            # Construct synthetic time axis starting at 0
            time_axis = np.concatenate(([0], np.cumsum(dt_diffs)))

            # 3. Calculate Acceleration (central difference)
            accel = np.gradient(step_speeds, time_axis)
            
            # 4. Calculate Yaw Rate
            yaw_rate_deg = np.zeros(n_steps)
            if 'ego_world_heading' in self.frame_metadata:
                ep_heading = self.frame_metadata['ego_world_heading'][start:end]
                if len(ep_heading) == n_steps:
                    # Unwrap phase to handle 2pi jumps
                    heading_unwrapped = np.unwrap(ep_heading)
                    yaw_rate_rad = np.gradient(heading_unwrapped, time_axis)
                    yaw_rate_deg = np.degrees(yaw_rate_rad)
            
            # --- Plotting ---
            # Acceleration on Left Axis
            ln1 = ax4.plot(steps, accel, color='#FFC107', linewidth=1.5, label='Accel ($m/s^2$)')
            ax4.fill_between(steps, 0, accel, color='#FFC107', alpha=0.15)
            ax4.set_ylabel('Acceleration ($m/s^2$)', color='#FFC107')
            ax4.tick_params(axis='y', labelcolor='#FFC107')
            
            # Yaw Rate on Right Axis
            ax4_yaw = ax4.twinx()
            ln2 = ax4_yaw.plot(steps, yaw_rate_deg, color='#9C27B0', linewidth=1.2, 
                               alpha=0.8, label='Yaw Rate (deg/s)')
            ax4_yaw.set_ylabel('Yaw Rate (deg/s)', color='#9C27B0')
            ax4_yaw.tick_params(axis='y', labelcolor='#9C27B0')
            ax4_yaw.spines['right'].set_visible(True)
            
            ax4.set_title('Vehicle Dynamics', fontsize=11)
            
            # Combined Legend
            lns = ln1 + ln2
            labs = [l.get_label() for l in lns]
            ax4.legend(lns, labs, loc='upper left', fontsize=8)
            
        else:
            # Fallback: raw action magnitude
            action_norms = np.linalg.norm(actions, axis=1)
            steps = np.arange(len(action_norms))
            ax4.plot(steps, action_norms, color='#4CAF50', linewidth=1)
            ax4.fill_between(steps, 0, action_norms, color='#4CAF50', alpha=0.15)
            ax4.set_title('Action Magnitude', fontsize=11)
            ax4.set_ylabel('||action||')
        
        ax4.set_xlabel('Step')
        ax4.grid(True, alpha=0.2)
        
        # ================================================================
        # Row 3: Surround Camera Images (2×3 grid)
        # ================================================================
        # Determine the snapshot global index for image lookup
        if is_traj:
            snap_global_idx = start + snap_idx
        else:
            snap_global_idx = start + n_steps // 2
        
        if show_extra and show_cameras:
            # Camera arrangement:
            #   Row 0: [FRONT_LEFT] [FRONT] [FRONT_RIGHT]
            #   Row 1: [BACK_LEFT]  [BACK]  [BACK_RIGHT]
            cam_grid_row_start = 2  # gridspec row index
            cam_layout = [
                ('CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT'),
                ('CAM_BACK_LEFT',  'CAM_BACK',  'CAM_BACK_RIGHT'),
            ]
            
            image_paths = self.get_image_paths(snap_global_idx)
            
            for row_offset, cam_row in enumerate(cam_layout):
                for col_idx, cam_name in enumerate(cam_row):
                    ax_cam = fig.add_subplot(gs[cam_grid_row_start + row_offset, col_idx * 2:(col_idx + 1) * 2])
                    
                    img_path = image_paths.get(cam_name)
                    if img_path and os.path.isfile(img_path):
                        try:
                            from PIL import Image
                            img = Image.open(img_path)
                            ax_cam.imshow(img)
                        except ImportError:
                            import matplotlib.image as mpimg
                            img = mpimg.imread(img_path)
                            ax_cam.imshow(img)
                        except Exception as e:
                            ax_cam.text(0.5, 0.5, f'Error: {e}',
                                        ha='center', va='center', transform=ax_cam.transAxes,
                                        fontsize=8, color='red')
                    else:
                        ax_cam.text(0.5, 0.5, 'No Image',
                                    ha='center', va='center', transform=ax_cam.transAxes,
                                    fontsize=10, color='gray')
                        ax_cam.set_facecolor('#F0F0F0')
                    
                    # Label
                    short_name = cam_name.replace('CAM_', '').replace('_', ' ')
                    ax_cam.set_title(short_name, fontsize=9, pad=2)
                    ax_cam.set_xticks([])
                    ax_cam.set_yticks([])
        
        # ================================================================
        # Row 4: QA Annotations (text box for nearest keyframe)
        # ================================================================
        if show_extra and show_qa_row:
            qa_grid_row = n_grid_rows - 1  # last row
            ax_qa = fig.add_subplot(gs[qa_grid_row, :])
            ax_qa.set_axis_off()
            
            # Find QA items for the nearest keyframe to the snapshot step
            snap_qa_items = self._find_nearest_qa(snap_global_idx)
            
            if snap_qa_items:
                # Format QA text
                lines = []
                # Show keyframe info
                if 'is_sample' in self.frame_metadata:
                    is_kf = self.frame_metadata['is_sample'][snap_global_idx]
                    if not is_kf:
                        # Find the nearest keyframe index
                        kf_step = snap_qa_items[0].get('step_index', snap_global_idx)
                        lines.append(f"[QA from nearest keyframe  step={kf_step}]")
                    else:
                        lines.append(f"[QA at keyframe  step={snap_global_idx}]")
                
                max_display = 8  # Show up to 8 QA pairs
                for i, qa in enumerate(snap_qa_items[:max_display]):
                    q = qa.get('question', '?')
                    a = qa.get('answer', '?')
                    t = qa.get('template_type', '')
                    lines.append(f"Q{i+1} [{t}]: {q}")
                    lines.append(f"  A: {a}")
                
                remaining = len(snap_qa_items) - max_display
                if remaining > 0:
                    lines.append(f"  ... and {remaining} more QA items")
                
                qa_text = '\n'.join(lines)
            else:
                qa_text = "(No QA annotations found for this frame or nearby keyframes)"
            
            ax_qa.text(0.02, 0.95, qa_text,
                       transform=ax_qa.transAxes,
                       fontsize=8.5, fontfamily='monospace',
                       verticalalignment='top', horizontalalignment='left',
                       bbox=dict(boxstyle='round,pad=0.5', facecolor='#F8F8F0',
                                 edgecolor='#CCCCCC', alpha=0.95))
            ax_qa.set_title('QA Annotations', fontsize=11, pad=4)
        
        # ================================================================
        # Finalize
        # ================================================================
        freq = self.attrs.get('frequency', 'unknown')
        hist_s = self.attrs.get('history_sec', '?')
        fut_s = self.attrs.get('future_sec', '?')
        cost_type = self.attrs.get('cost_type', 'none')
        map_str = '  map=yes' if self.has_map else ''
        img_str = '  img=yes' if self.has_images else ''
        
        # Scene name for the snapshot
        scene_str = ''
        if 'scene_names' in self.frame_metadata:
            scene_str = f'  scene={self.frame_metadata["scene_names"][snap_global_idx]}'
        
        fig.suptitle(
            f'Episode {episode_idx}  |  freq={freq}  |  '
            f'history={hist_s}s  future={fut_s}s  |  cost={cost_type}{map_str}{img_str}{scene_str}',
            fontsize=12, y=0.99
        )
        
        if show_extra:
            plt.subplots_adjust(top=0.96)
        else:
            plt.tight_layout(rect=[0, 0, 1, 0.96])
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"Saved visualization to: {save_path}")
        else:
            plt.show()
    
    def visualize_observation_distribution(self, save_path: Optional[str] = None):
        """Visualize observation and action distributions."""
        try:
            import matplotlib.pyplot as plt
        except ImportError:
            print("Error: matplotlib required for visualization")
            return
        
        if 'observations' not in self.data:
            print("No observation data")
            return
        
        obs = self.data['observations']
        is_traj = self._is_trajectory_format()
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 11))
        
        # ================================================================
        # Plot 1 (Top-Left): Ego history — xy scatter of past positions
        # ================================================================
        ax1 = axes[0, 0]
        
        if is_traj:
            history_steps = int(self.attrs.get('history_steps', 6))
            # For each history step, scatter (x, y) across all observations
            cmap = plt.cm.Blues
            for h in range(history_steps):
                offset = h * 5
                hx = obs[:, offset + 0]
                hy = obs[:, offset + 1]
                # Filter out zero-padded entries
                mask = (np.abs(hx) > 1e-6) | (np.abs(hy) > 1e-6) | (h == history_steps - 1)
                color = cmap(0.3 + 0.7 * h / max(1, history_steps - 1))
                label = f't-{history_steps - 1 - h}' if h < history_steps - 1 else 't (current)'
                ax1.scatter(hx[mask], hy[mask], color=color, s=3, alpha=0.15, label=label)
            
            ax1.scatter(0, 0, color='#FFC107', s=80, marker='o', edgecolors='black',
                       linewidths=1, zorder=6, label='Ego origin')
            ax1.set_xlabel('X (m, local frame)')
            ax1.set_ylabel('Y (m, local frame)')
            ax1.set_title('Ego History Position Distribution', fontsize=11)
            ax1.set_aspect('equal')
            ax1.legend(fontsize=7, markerscale=3, loc='upper left')
        else:
            means = obs.mean(axis=0)
            stds = obs.std(axis=0)
            dims = np.arange(len(means))
            ax1.bar(dims, means, alpha=0.7, label='Mean')
            ax1.errorbar(dims, means, yerr=stds, fmt='none', color='red', capsize=1, label='Std')
            ax1.set_xlabel('Dimension')
            ax1.set_ylabel('Value')
            ax1.set_title('Observation Statistics per Dimension')
            ax1.legend()
        
        ax1.grid(True, alpha=0.2)
        
        # ================================================================
        # Plot 2 (Top-Right): Future waypoint position scatter
        # ================================================================
        ax2 = axes[0, 1]
        
        if is_traj and 'actions' in self.data:
            actions = self.data['actions']
            future_steps = int(self.attrs.get('future_steps', 24))
            
            # Decode all actions -> (N, future_steps, 5)
            n_samples_vis = min(500, len(actions))  # limit for scatter
            sample_idx = np.random.choice(len(actions), n_samples_vis, replace=False)
            
            for idx in sample_idx:
                wp = self._decode_trajectory_action(actions[idx])
                ax2.plot(wp[:, 0], wp[:, 1], color='#4CAF50', alpha=0.03, linewidth=0.5)
            
            # Draw mean trajectory
            all_wp = np.array([self._decode_trajectory_action(actions[i])[:, :2]
                              for i in sample_idx])
            mean_wp = all_wp.mean(axis=0)
            ax2.plot(mean_wp[:, 0], mean_wp[:, 1], color='#F44336',
                     linewidth=2.5, label='Mean trajectory', zorder=5)
            ax2.scatter(0, 0, color='#FFC107', s=100, marker='o',
                       edgecolors='black', linewidths=1, label='Ego', zorder=6)
            
            ax2.set_xlabel('X (m, local frame)')
            ax2.set_ylabel('Y (m, local frame)')
            ax2.set_title(f'Future Waypoints Distribution ({n_samples_vis} samples)', fontsize=11)
            ax2.set_aspect('equal')
            ax2.legend(fontsize=9)
        else:
            if 'actions' in self.data:
                act = self.data['actions']
                for i in range(min(3, act.shape[1])):
                    ax2.hist(act[:, i], bins=50, alpha=0.5, label=f'Dim {i}')
                ax2.set_title('Action Distribution')
                ax2.legend()
            else:
                ax2.text(0.5, 0.5, 'No action data', ha='center', va='center',
                         transform=ax2.transAxes)
        
        ax2.grid(True, alpha=0.2)
        
        # ================================================================
        # Plot 3 (Bottom-Left): Ego speed distribution
        # ================================================================
        ax3 = axes[1, 0]
        
        if is_traj:
            history_steps = int(self.attrs.get('history_steps', 6))
            # Extract ego current-step features from all observations
            # Current step is the last row of ego history: index = (history_steps-1) * 5
            current_offset = (history_steps - 1) * 5
            ego_x = obs[:, current_offset + 0]      # should be ~0 (current pos)
            ego_y = obs[:, current_offset + 1]      # should be ~0
            ego_vx = obs[:, current_offset + 2]
            ego_vy = obs[:, current_offset + 3]
            ego_speed = np.sqrt(ego_vx**2 + ego_vy**2)
            
            ax3.hist(ego_speed, bins=60, color='#2196F3', alpha=0.7, edgecolor='white', linewidth=0.3)
            ax3.axvline(ego_speed.mean(), color='#F44336', linestyle='--', linewidth=1.5,
                       label=f'Mean: {ego_speed.mean():.2f} m/s')
            ax3.set_xlabel('Speed (m/s)')
            ax3.set_ylabel('Count')
            ax3.set_title('Ego Speed Distribution', fontsize=11)
            ax3.legend(fontsize=9)
        else:
            n_dims = min(20, obs.shape[1])
            corr = np.corrcoef(obs[:, :n_dims].T)
            im = ax3.imshow(corr, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)
            ax3.set_xlabel('Dimension')
            ax3.set_ylabel('Dimension')
            ax3.set_title(f'Observation Correlation (first {n_dims} dims)')
            plt.colorbar(im, ax=ax3)
        
        ax3.grid(True, alpha=0.2)
        
        # ================================================================
        # Plot 4 (Bottom-Right): Heading change distribution
        # ================================================================
        ax4 = axes[1, 1]
        
        if is_traj and 'actions' in self.data:
            actions = self.data['actions']
            future_steps = int(self.attrs.get('future_steps', 24))
            
            # Extract heading change from actions: waypoint heading relative to ego
            headings_final = []
            headings_first = []
            for i in range(len(actions)):
                wp = self._decode_trajectory_action(actions[i])
                headings_first.append(wp[0, 4])   # heading of first future step
                headings_final.append(wp[-1, 4])   # heading of last future step
            
            headings_first = np.array(headings_first)
            headings_final = np.array(headings_final)
            
            ax4.hist(np.degrees(headings_first), bins=60, color='#4CAF50', alpha=0.6,
                     edgecolor='white', linewidth=0.3, label='First waypoint')
            ax4.hist(np.degrees(headings_final), bins=60, color='#9C27B0', alpha=0.5,
                     edgecolor='white', linewidth=0.3, label='Final waypoint')
            ax4.set_xlabel('Heading Change (degrees)')
            ax4.set_ylabel('Count')
            ax4.set_title('Future Heading Change Distribution', fontsize=11)
            ax4.legend(fontsize=9)
        else:
            if 'actions' in self.data:
                act = self.data['actions']
                norms = np.linalg.norm(act, axis=1)
                ax4.hist(norms, bins=60, color='#4CAF50', alpha=0.7, edgecolor='white')
                ax4.set_xlabel('||action||')
                ax4.set_ylabel('Count')
                ax4.set_title('Action Magnitude Distribution')
            else:
                ax4.text(0.5, 0.5, 'No action data', ha='center', va='center',
                         transform=ax4.transAxes)
        
        ax4.grid(True, alpha=0.2)
        
        # Finalize
        freq = self.attrs.get('frequency', 'unknown')
        fig.suptitle(f'Data Distribution  |  freq={freq}  |  N={len(obs)} steps',
                     fontsize=12, y=0.98)
        plt.tight_layout(rect=[0, 0, 1, 0.96])
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"Saved visualization to: {save_path}")
        else:
            plt.show()


def list_datasets(output_dir: str) -> List[str]:
    """List available datasets."""
    print("=" * 70)
    print(f"Available datasets in: {output_dir}")
    print("=" * 70)
    
    if not os.path.exists(output_dir):
        print("  (directory does not exist)")
        return []
    
    files = []
    for f in os.listdir(output_dir):
        if f.endswith('.h5') or f.endswith('.npz'):
            filepath = os.path.join(output_dir, f)
            size = os.path.getsize(filepath) / 1024  # KB
            files.append((f, size))
    
    if not files:
        print("  (no datasets found)")
        return []
    
    for f, size in sorted(files):
        if size > 1024:
            print(f"  {f} ({size/1024:.1f} MB)")
        else:
            print(f"  {f} ({size:.1f} KB)")
    
    return [f[0] for f in files]


def resolve_filepath(filepath: str) -> Optional[str]:
    """Resolve filepath to absolute path."""
    if os.path.isabs(filepath):
        return filepath if os.path.exists(filepath) else None
    
    # Try relative to project root
    path = os.path.join(project_root, filepath)
    if os.path.exists(path):
        return path
    
    # Try relative to DEFAULT_OUTPUT_DIR
    path = os.path.join(DEFAULT_OUTPUT_DIR, filepath)
    if os.path.exists(path):
        return path
    
    # Try current directory
    if os.path.exists(filepath):
        return os.path.abspath(filepath)
    
    return None


def parse_args():
    parser = argparse.ArgumentParser(
        description="Read and visualize offline RL datasets with trajectory-based observations/actions",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Visualization Features:
  --visualize: Episode trajectory view (ego-centric)
    • Ego-centric snapshot: single timestep centered on ego vehicle
    • Map features background: lanes, road lines, crosswalks, road edges
    • Blue dashed: historical trajectory
    • Green solid: future waypoints with increasing marker size
    • Yellow: current ego position with heading arrow
    • Red squares: surrounding vehicles with history trails
    • Velocity profile, rewards/costs, and trajectory reach plots

  --visualize_dist: Data distribution analysis
    • Ego speed histogram across dataset
    • Future waypoints 2D scatter (500 samples overlay)
    • Historical positions scatter colored by timestep
    • Heading change distribution

Examples:
  # Show dataset info and statistics
  python -m meta_qa.scripts.data_collect.read_data --file data.h5
  
  # List all available datasets
  python -m meta_qa.scripts.data_collect.read_data --list
  
  # Visualize episode trajectory (centered on ego)
  python -m meta_qa.scripts.data_collect.read_data --file data.h5 --visualize --episode 5
  
  # Visualize data distributions
  python -m meta_qa.scripts.data_collect.read_data --file data.h5 --visualize_dist
  
  # Save visualization to file
  python -m meta_qa.scripts.data_collect.read_data --file data.h5 --visualize --save_fig output.png
  
  # Show QA annotations
  python -m meta_qa.scripts.data_collect.read_data --file data.h5 --show_qa --max_qa 10
  
  # Print sample data points
  python -m meta_qa.scripts.data_collect.read_data --file data.h5 --samples 5 --start 100
"""
    )
    
    parser.add_argument("--file", "-f", type=str, default=None,
                       help="Dataset file path (HDF5 or NPZ, absolute or relative)")
    parser.add_argument("--list", "-l", action="store_true",
                       help="List available datasets in output directory")
    parser.add_argument("--samples", "-s", type=int, default=3,
                       help="Number of sample data points to print (default: 3)")
    parser.add_argument("--start", type=int, default=0,
                       help="Starting index for sample printing (default: 0)")
    parser.add_argument("--show_qa", action="store_true",
                       help="Display QA annotations")
    parser.add_argument("--max_qa", type=int, default=20,
                       help="Maximum QA items to display (default: 20)")
    parser.add_argument("--visualize", "-v", action="store_true",
                       help="Visualize episode trajectory (ego-centric view)")
    parser.add_argument("--visualize_dist", action="store_true",
                       help="Visualize observation/action distributions")
    parser.add_argument("--episode", "-e", type=int, default=0,
                       help="Episode index to visualize")
    parser.add_argument("--save_fig", type=str, default=None,
                       help="Save visualization to file")
    parser.add_argument("--no_info", action="store_true",
                       help="Skip dataset info printing")
    
    return parser.parse_args()


def main():
    args = parse_args()
    
    # List datasets
    if args.list or args.file is None:
        files = list_datasets(DEFAULT_OUTPUT_DIR)
        if args.file is None and files:
            print(f"\nUse --file <filename> to inspect a dataset")
        if args.file is None:
            return
    
    # Resolve file path
    filepath = resolve_filepath(args.file)
    if filepath is None:
        print(f"Error: File not found: {args.file}")
        print(f"  Tried:")
        print(f"    - {args.file}")
        print(f"    - {os.path.join(project_root, args.file)}")
        print(f"    - {os.path.join(DEFAULT_OUTPUT_DIR, args.file)}")
        return
    
    print(f"\nLoading: {filepath}\n")
    
    try:
        reader = OfflineDataReader(filepath)
    except Exception as e:
        print(f"Error loading dataset: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # Print info
    if not args.no_info:
        reader.print_info()
    
    # Print samples
    if args.samples > 0 and not args.no_info:
        reader.print_samples(n_samples=args.samples, start_idx=args.start)
    
    # Show QA data
    if args.show_qa:
        reader.print_qa_data(max_items=args.max_qa)
    
    # Visualize trajectory
    if args.visualize:
        reader.visualize_episode(episode_idx=args.episode, save_path=args.save_fig)
    
    # Visualize distribution
    if args.visualize_dist:
        save_path = args.save_fig
        if save_path and args.visualize:
            # Different filename for distribution plot
            base, ext = os.path.splitext(save_path)
            save_path = f"{base}_dist{ext}"
        reader.visualize_observation_distribution(save_path=save_path)
    
    print("\nDone!")


if __name__ == "__main__":
    main()
